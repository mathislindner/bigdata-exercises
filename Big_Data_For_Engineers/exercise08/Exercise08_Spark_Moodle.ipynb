{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Big Data for Engineers – Exercises</center>\n",
    "## <center>Spring 2022 – Week 8 – ETH Zurich</center>\n",
    "## <center>Notebook for the Spark Moodle Quiz</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start docker\n",
    "\n",
    "In your exercise 08 directory, start docker\n",
    "\n",
    "```\n",
    "docker compose up\n",
    "```\n",
    "\n",
    "After docker finishes downloading the images, you should be able to start the jupyter notebook by copying the following URL to your browser\n",
    "\n",
    "```\n",
    "http://127.0.0.1:8888/lab\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=test, master=local) created by __init__ at /tmp/ipykernel_128/2200975250.py:4 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkContext\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# sc is the Spark Context object \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/context.py:198\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m     )\n\u001b[0;32m--> 198\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    201\u001b[0m         master,\n\u001b[1;32m    202\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m         memory_profiler_cls,\n\u001b[1;32m    213\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/context.py:445\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    442\u001b[0m     callsite \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\u001b[38;5;241m.\u001b[39m_callsite\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;66;03m# Raise error if there is already a running Spark context\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot run multiple SparkContexts at once; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting SparkContext(app=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, master=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m created by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    450\u001b[0m             currentAppName,\n\u001b[1;32m    451\u001b[0m             currentMaster,\n\u001b[1;32m    452\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[1;32m    453\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfile,\n\u001b[1;32m    454\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mlinenum,\n\u001b[1;32m    455\u001b[0m         )\n\u001b[1;32m    456\u001b[0m     )\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;241m=\u001b[39m instance\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=test, master=local) created by __init__ at /tmp/ipykernel_128/2200975250.py:4 "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.context import SparkContext\n",
    "# sc is the Spark Context object \n",
    "sc = SparkContext('local', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 44.55712890625,
      "end_time": 1557044256642.663
     }
    }
   },
   "source": [
    "### The Moodle Quiz\n",
    "\n",
    "For this quiz we will be using the [language confusion dataset](https://quietlyamused.org/blog/2014/03/12/language-confusion/).\n",
    "\n",
    "As mentioned in the exercise, this quiz is a part of the small project you will be doing over the following 3 weeks to compare Spark, Spark with DataFrames/SQL, and JSONiq. You will hear more about it in the coming weeks.\n",
    "\n",
    "For the Moodle quiz we ask you to submit the following things:\n",
    "- The query you wrote (although it is not graded, having your query is helpful for arguing about points)\n",
    "- Something related to its output (**the only part that is graded**)\n",
    "- The time it took you to write it (thinking time)\n",
    "- The time it took you to run it (execution time)\n",
    "\n",
    "You don't need to submit this notebook, only the queries you wrote.\n",
    "\n",
    "On your own laptop, download and decompress the dataset into the ex08 folder using the commands below. You can also copy the URL to your browser to download it, then decompress it using the default decompression tools Windows/Mac. Alternatively, you can also run the commands in jupyter notebook, but it takes several minutes to decompress it in the docker container.\n",
    "\n",
    "```bash\n",
    "wget https://cloud.inf.ethz.ch/s/a8FoHew6dHKGYKK/download/confusion20140302.tbz2; tar -jxvf confusion20140302.tbz2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:07:34.367427Z",
     "start_time": "2021-05-03T17:07:33.474055Z"
    },
    "cell_status": {
     "execute_time": {
      "duration": 747.39990234375,
      "end_time": 1619999839916.484
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = sc.textFile('./confusion-2014-03-02/confusion-2014-03-02.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the entries are JSON records, you will need to parse them and use their respective object representations. You can use this mapping for all queries. Since some of the queries take a long time to execute on the dataset, you may want to answer these queries on the first `100000` entries. \n",
    "\n",
    "**For the quiz, fill in the results by running the queries on the 100000-entry subset (`test_entries` as defined in the following cell) instead of the entire dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:11:24.581153Z",
     "start_time": "2021-05-03T17:11:23.900172Z"
    },
    "cell_status": {
     "execute_time": {
      "duration": 5296.226806640625,
      "end_time": 1619999845222.09
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'guess': 'Norwegian', 'target': 'Norwegian', 'country': 'AU', 'choices': ['Maori', 'Mandarin', 'Norwegian', 'Tongan'], 'sample': '48f9c924e0d98c959d8a6f1862b3ce9a', 'date': '2013-08-19'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "testset = sc.parallelize(data.take(100000))\n",
    "test_entries = testset.map(json.loads)\n",
    "print(test_entries.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Let's get to work. A few last things:\n",
    "- Take into account that some of the queries might have very large outputs, which Jupyter (or sometimes even Spark) won't be able to handle. It is normal for the queries to take some time, but if the notebook crashes or stops responding, try restarting the kernel. Avoid printing large outputs. You can print the first few entries to confirm the query has worked, as shown in query 1.\n",
    "- Remember to delete the cluster if you want to stop working! You can recreate it using the same container name and your resources will still be there.\n",
    "- Refer to the [documentation](http://spark.apache.org/docs/2.3.0/api/python/pyspark.html#pyspark.RDD), as well as the programming guides on actions and transformations linked to above.\n",
    "\n",
    "And now to the actual queries: *Please make sure that in your queries you *only* use PySpark, and avoid any dataframes (they will covered in next week's exercises)*\n",
    "\n",
    "1\\. Find all games such that the guessed language is correct (=target), and such that this language is Spanish. What is the length of the resulting sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T15:31:40.763220Z",
     "start_time": "2021-05-03T15:31:40.039089Z"
    },
    "cell_status": {
     "execute_time": {
      "duration": 2256.77880859375,
      "end_time": 1619999854080.019
     }
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 2094\n",
      "Time consumption 0.5120983123779297 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Query:\n",
    "matching = test_entries.filter(lambda e: e[\"target\"] == \"Spanish\" and e[\"guess\"] == \"Spanish\").collect()\n",
    "end = time.time()\n",
    "print('length =', len(matching))\n",
    "print('Time consumption {} sec'.format(end - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Find the number of all distinct values of the *guessed* languages (i.e. the *guess* field). What is the length of the resulting sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T15:34:36.715804Z",
     "start_time": "2021-05-03T15:34:35.945578Z"
    },
    "cell_status": {
     "execute_time": {
      "duration": 1249.218017578125,
      "end_time": 1619999878828.007
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Norwegian', 'Dinka', 'Samoan', 'Somali', 'Japanese', 'Turkish', 'French', 'German', 'Spanish', 'Romanian', 'Cantonese', 'Assyrian', 'Hebrew', 'Kurdish', 'Italian', 'Maltese', 'Kannada', 'Albanian', 'Lao', 'Swahili', 'Vietnamese', 'Portuguese', 'Nepali', 'Indonesian', 'Finnish', 'Fijian', 'Burmese', 'Khmer', 'Polish', 'Dutch', 'Russian', 'Estonian', 'Serbian', 'Tagalog', 'Slovenian', 'Latvian', 'Czech', 'Urdu', 'Tigrinya', 'Tamil', 'Danish', 'Mandarin', 'Armenian', 'Sinhalese', 'Bangla', 'Arabic', 'Punjabi', 'Hindi', 'Dari', 'Tongan', 'Malay', 'Farsi', 'Ukrainian', 'Greek', 'Maori', 'Gujarati', 'Yiddish', 'Macedonian', 'Swedish', 'Korean', 'Bulgarian', 'Slovak', 'Amharic', 'Bosnian', 'Hungarian', 'Malayalam', 'Croatian', 'Thai']\n",
      "68\n",
      "Time consumption 1.1223254203796387 sec\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_set\n",
    "start = time.time()\n",
    "# Query:\n",
    "#matching = test_entries.map(lambda e: e[\"target\"]).reduce(lambda x,y: set(y))\n",
    "matching = test_entries.map(lambda e: e[\"target\"]).distinct().collect()\n",
    "end = time.time()\n",
    "print(matching)\n",
    "print(len(matching))\n",
    "print('Time consumption {} sec'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Return the top three games where the guessed language is incorrect ($\\ne$target) ordered by country (ascending), then target language (ascending), then date (ascending). What is the sample id of the 3rd item in the list? \n",
    "\n",
    "Enter it without quotes, for example 48f9c924e0d98c959d8a6f1862b3ce9a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T15:35:23.809109Z",
     "start_time": "2021-05-03T15:35:21.827970Z"
    },
    "cell_status": {
     "execute_time": {
      "duration": 2255.52197265625,
      "end_time": 1619999884156.929
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00b85faa8b878a14f8781be334deb137\n",
      "Time consumption 1.0367622375488281 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Query:\n",
    "wrong_guesses = test_entries.filter(lambda e: e[\"target\"] != e[\"guess\"])\n",
    "ordered_by_date  = wrong_guesses.sortBy(lambda e: e[\"date\"], ascending = True )\n",
    "ordered_by_target_language = ordered_by_date.sortBy(lambda e: e[\"target\"], ascending = True )\n",
    "ordered_by_country = ordered_by_target_language.sortBy(lambda e: e[\"country\"], ascending = True )\n",
    "result = ordered_by_country.collect()\n",
    "print(result[2][\"sample\"])\n",
    "end = time.time()\n",
    "print('Time consumption {} sec'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Aggregate all games by guessed and target language, counting the number of guessing games that were done for each pair (guess, target). How many times has Dutch been mistaken for Norwegian (i.e. Dutch was the true answer)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T15:40:43.495660Z",
     "start_time": "2021-05-03T15:40:42.877495Z"
    },
    "cell_status": {
     "execute_time": {
      "duration": 744.037109375,
      "end_time": 1619999964374.737
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Time consumption 0.4961109161376953 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Query:\n",
    "#aggregation = test_entries.groupBy(\"target\",\"guess\").count()\n",
    "#mistaken = aggregation.filter(lambda e: e[\"target\"] == \"Dutch\" and e[\"guess\"] == \"Norvegian\")\n",
    "#result = mistaken.collect()\n",
    "matching = test_entries.filter(lambda e: e[\"target\"] == \"Dutch\" and e[\"guess\"] == \"Norwegian\").collect()\n",
    "print(len(matching))\n",
    "#print(result)\n",
    "end = time.time()\n",
    "print('Time consumption {} sec'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Among all the games where the guess was correct (=target), what is the percentage of cases where the second choice (among the array of possible answers) was the target?\n",
    "\n",
    "Please write the fraction rounding to 4 decimals (eg. 0.3323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T15:44:38.257988Z",
     "start_time": "2021-05-03T15:44:37.238548Z"
    },
    "cell_status": {
     "execute_time": {
      "duration": 1265.596923828125,
      "end_time": 1620000286240.596
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37891275334002944\n",
      "Time consumption 1.757666826248169 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Query:\n",
    "correct_guesses_count = test_entries.filter(lambda e: e[\"target\"] == e[\"guess\"]).count()\n",
    "correct_guesses = test_entries.filter(lambda e: e[\"target\"] == e[\"guess\"])\n",
    "second_choice_is_target_count = correct_guesses.filter(lambda e: e[\"choices\"][1] == e[\"target\"]).count()\n",
    "print(second_choice_is_target_count/correct_guesses_count)\n",
    "end = time.time()\n",
    "print('Time consumption {} sec'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. For each target language, compute the percentage of successful guess games (i.e. *guess* == *target*) relative to all games for that target language, and display the pairs `(target_language, percentage)` in descending order of the percentage. What is the third language in this list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T15:46:03.514495Z",
     "start_time": "2021-05-03T15:46:02.433609Z"
    },
    "cell_status": {
     "execute_time": {
      "duration": 1261.2919921875,
      "end_time": 1620000145674.288
     }
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('French', 95.97374179431073), ('German', 94.55670103092784), ('Mandarin', 92.7967985771454), ('Spanish', 92.77802392556491), ('Cantonese', 92.01053555750659), ('Italian', 91.94690265486726), ('Japanese', 91.11008751727314), ('Korean', 89.9624765478424), ('Russian', 88.50305021116847), ('Vietnamese', 86.93492300049677), ('Arabic', 85.48942449581898), ('Thai', 85.03937007874016), ('Ukrainian', 81.30412633723893), ('Hebrew', 79.55334987593052), ('Lao', 77.89580171977744), ('Polish', 77.0517511761631), ('Czech', 76.11379495437467), ('Norwegian', 75.75593952483801), ('Slovak', 74.6218487394958), ('Swedish', 74.40217391304348), ('Romanian', 74.33070866141732), ('Greek', 73.39901477832512), ('Swahili', 72.66666666666667), ('Portuguese', 72.5958866036687), ('Yiddish', 72.52124645892351), ('Slovenian', 72.13525360050095), ('Punjabi', 71.11111111111111), ('Gujarati', 71.08208955223881), ('Bulgarian', 71.03494623655914), ('Danish', 70.71990320629159), ('Dutch', 69.37463471654003), ('Khmer', 68.77551020408163), ('Serbian', 68.58974358974359), ('Latvian', 66.92634560906515), ('Tagalog', 66.79127725856698), ('Burmese', 66.74528301886792), ('Tamil', 66.68941979522184), ('Finnish', 65.55869872701555), ('Kurdish', 65.44776119402985), ('Macedonian', 64.10066617320503), ('Malayalam', 63.89351081530782), ('Bosnian', 63.50931677018634), ('Urdu', 63.08724832214765), ('Armenian', 62.72189349112426), ('Assyrian', 61.75972927241963), ('Estonian', 61.333333333333336), ('Farsi', 61.21212121212121), ('Albanian', 60.9375), ('Croatian', 60.738255033557046), ('Tongan', 60.16597510373444), ('Somali', 59.32062966031483), ('Hindi', 58.144126357354395), ('Hungarian', 56.653992395437264), ('Bangla', 56.02094240837696), ('Turkish', 55.520833333333336), ('Samoan', 55.04014272970562), ('Malay', 53.714285714285715), ('Nepali', 52.396878483835), ('Indonesian', 51.07398568019093), ('Sinhalese', 49.93773349937734), ('Amharic', 49.22077922077922), ('Maltese', 48.24242424242424), ('Tigrinya', 47.995139732685296), ('Maori', 47.8502080443828), ('Dari', 47.293447293447294), ('Kannada', 43.4654919236417), ('Fijian', 42.6367461430575), ('Dinka', 41.94053208137715)]\n",
      "Time consumption 0.8619465827941895 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Query:\n",
    "mapping = test_entries.map(lambda e: (e[\"target\"], (1, int(e[\"target\"] == e[\"guess\"]))))\n",
    "reducing = mapping.reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "result_rdd = reducing.map(lambda x: (x[0], 100 * x[1][1] / x[1][0])).sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "results = result_rdd.collect()\n",
    "print(results)\n",
    "    \n",
    "end = time.time()\n",
    "print('Time consumption {} sec'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. How many games in France (country=FR) were played on the last day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:23:10.632593Z",
     "start_time": "2021-05-03T17:23:08.538836Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n",
      "Time consumption 1.1423659324645996 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Query:\n",
    "ditinct_dates = test_entries.map(lambda e: e[\"date\"]).distinct().collect()\n",
    "last_day = (max(ditinct_dates))\n",
    "matching = test_entries.filter(lambda e: e[\"date\"] == last_day and e[\"country\"] == \"FR\").collect()\n",
    "print(len(matching))\n",
    "end = time.time()\n",
    "print('Time consumption {} sec'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Big Data &ndash; Exercises</center>\n",
    "## <center>Spring 2022 &ndash; Week 9 &ndash; ETH Zurich</center>\n",
    "## <center>Spark Dataframes and Spark SQL, Moodle exercise</center>\n",
    "\n",
    "# Preparation for the moodle exercise in Spark\n",
    "\n",
    "In this jupyter notebook we are going to make the preprocessing part of the dataset that is going to be used in the graded exercise of this week.\n",
    "It will be the same language game dataset as in exercise08.\n",
    "\n",
    "1. Change to `exercise09` repository\n",
    "\n",
    "2. Start docker <br>\n",
    "```docker-compose up -d```\n",
    "\n",
    "3. After docker finishes downloading the images, you should be able to start the jupyter notebook by copying the following URL to your browser <br>\n",
    "```http://localhost:8888/lab```\n",
    "\n",
    "4. Getting the data:\n",
    "Follow the procedure that is described below. The dataset can be found here: https://cloud.inf.ethz.ch/s/a8FoHew6dHKGYKK/download/confusion20140302.tbz2 \n",
    "\n",
    "More specifically do the following:\n",
    "- download the data      :<br> ```wget https://cloud.inf.ethz.ch/s/a8FoHew6dHKGYKK/download/confusion20140302.tbz2```\n",
    "- extract the data       :<br> ```tar -jxvf confusion20140302.tbz2```\n",
    "\n",
    "\n",
    "## More Info about the data\n",
    "You can find more information about the dataset (as well as the schema and examples) in this link: https://quietlyamused.org/blog/2014/03/12/language-confusion/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "In every query we ask you for three quantities: the query itself, the result of the query, the time it took you to write the query. Note that the time part of every question is optional and not graded. In order to make easier the time recording we created two functions that do it automatically. Run the cell below in order to import the functions into the current notebook. Then before each query we will have a ```start_exercise()``` cell that you have to run in order to start time recording. After you have finished your query and you are sure about the answer run the ```finish_exercise()``` one to get the time measurement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>For the assignments we only use the first 50k lines of the dataset, `dataset_50k = dataset.limit(50000)`. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 39.236083984375,
      "end_time": 1573672504782.379
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def start_exercise():\n",
    "    global last\n",
    "    last = time.time()\n",
    "    \n",
    "def finish_exercise():\n",
    "    global last\n",
    "    print(\"This exercise took {0}s\".format(int(time.time()-last)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>1. Spark Dataframes</center>\n",
    "\n",
    "Write queries for the same questions as last week, but this time using Spark Dataframes operations (the data loading will take a couple minutes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 11301.424072265625,
      "end_time": 1573676870300.81
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "path = \"confusion-2014-03-02/confusion-2014-03-02.json\"\n",
    "dataset = spark.read.json(path).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 247.257080078125,
      "end_time": 1573676894196.787
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+---------+--------------------+---------+\n",
      "|             choices|country|      date|    guess|              sample|   target|\n",
      "+--------------------+-------+----------+---------+--------------------+---------+\n",
      "|[Maori, Mandarin,...|     AU|2013-08-19|Norwegian|48f9c924e0d98c959...|Norwegian|\n",
      "|[Danish, Dinka, K...|     AU|2013-08-19|    Dinka|af5e8f27cef9e689a...|    Dinka|\n",
      "|[German, Hungaria...|     AU|2013-08-19|  Turkish|509c36eb58dbce009...|   Samoan|\n",
      "+--------------------+-------+----------+---------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test it out\n",
    "dataset.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_50k = dataset.limit(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "Find all games such that the guessed language is correct (=target), and such that this language is Spanish. What is the length of the resulting sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 951.284912109375,
      "end_time": 1573677112003.169
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "#dataset_50k.filter(\"target = 'Spanish' and guess = 'Spanish'\").count()\n",
    "a = dataset_50k.filter(dataset_50k[\"target\"] == 'Spanish')\n",
    "b = a.filter(a[\"guess\"] == 'Spanish')\n",
    "b.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 65s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "Find the number of all distinct values of the guessed languages (i.e. the guess field). What is the length of the resulting sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 751.157958984375,
      "end_time": 1573677210603.419
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_50k.select(\"guess\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 1s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "Return the top three games where the guessed language is incorrect ($\\ne$target) ordered by country (ascending), then target language (ascending), then date (ascending). What is the sample id of the 3rd item in the list? \n",
    "\n",
    "Enter it without quotes, for example 48f9c924e0d98c959d8a6f1862b3ce9a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 757.619140625,
      "end_time": 1573677388481.756
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sample='ccebbc271377f7173e39564c74901f7c'),\n",
       " Row(sample='7efab6f0c61694ba6e8aa72843d1bf15'),\n",
       " Row(sample='3520fdcdf2658685928fc37e72ab2134')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "dataset_50k.select(\"sample\").filter(\"guess != target\").orderBy(\n",
    "    dataset_50k[\"country\"].asc(), dataset_50k[\"target\"].asc(), dataset_50k[\"date\"].asc()\n",
    ").limit(3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 1s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "Aggregate all games by guessed and target language, counting the number of guessing games that were done for each pair (guess, target). How many times has Dutch been mistaken for Norwegian (i.e. Dutch was the true answer)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 1262.1181640625,
      "end_time": 1573677845774.178
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(guess='Dutch', target='Norwegian', count=9)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "dataset_50k.groupBy([\"guess\", \"target\"]).count().filter(\"target == 'Norwegian' and guess = 'Dutch'\").select(\"count\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 1s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5\n",
    "Among all the games where the guess was correct (=target), what is the percentage of cases where the second choice (among the array of possible answers) was the target?\n",
    "\n",
    "Please write the fraction rounding to 4 decimals (eg. 0.3323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 747.340087890625,
      "end_time": 1573678219912.345
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2696"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_50k.filter(\"choices[1] = target and target = guess\").count() / float(dataset_50k.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 2s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "How many games in France (country=FR) were played on the last day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 751.73388671875,
      "end_time": 1573679567817.314
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date = dataset_50k.agg({\"date\": \"max\"}).collect()[0][\"max(date)\"]\n",
    "dataset_50k.filter(dataset_50k[\"date\"] == max_date).filter(dataset_50k[\"country\"] == \"FR\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 1s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>2. Spark SQL</center>\n",
    "\n",
    "Write Spark SQL queries for the same questions as earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sparksql-magic\n",
      "  Downloading sparksql_magic-0.0.3-py36-none-any.whl (4.3 kB)\n",
      "Requirement already satisfied: pyspark>=2.3.0 in /usr/local/spark-3.4.0-bin-hadoop3/python (from sparksql-magic) (3.4.0)\n",
      "Requirement already satisfied: ipython>=7.4.0 in /opt/conda/lib/python3.10/site-packages (from sparksql-magic) (8.13.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=7.4.0->sparksql-magic) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.4.0->sparksql-magic) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.4.0->sparksql-magic) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=7.4.0->sparksql-magic) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=7.4.0->sparksql-magic) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.4.0->sparksql-magic) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.4.0->sparksql-magic) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.4.0->sparksql-magic) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.4.0->sparksql-magic) (5.9.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.4.0->sparksql-magic) (4.8.0)\n",
      "Collecting py4j==0.10.9.7 (from pyspark>=2.3.0->sparksql-magic)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.4.0->sparksql-magic) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.4.0->sparksql-magic) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.4.0->sparksql-magic) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.4.0->sparksql-magic) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.4.0->sparksql-magic) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.4.0->sparksql-magic) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=7.4.0->sparksql-magic) (1.16.0)\n",
      "Installing collected packages: py4j, sparksql-magic\n",
      "Successfully installed py4j-0.10.9.7 sparksql-magic-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install sparksql-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparksql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 15326.347900390625,
      "end_time": 1573674838228.037
     }
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"confusion-2014-03-02/confusion-2014-03-02.json\"\n",
    "dataset_50k = spark.read.json(path).cache().limit(50000)\n",
    "dataset_50k.createOrReplaceTempView(\"dataset_50k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 19343.071044921875,
      "end_time": 1573674865742.795
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">choices</td><td style=\"font-weight: bold\">country</td><td style=\"font-weight: bold\">date</td><td style=\"font-weight: bold\">guess</td><td style=\"font-weight: bold\">sample</td><td style=\"font-weight: bold\">target</td></tr><tr><td>[&#x27;Maori&#x27;, &#x27;Mandarin&#x27;, &#x27;Norwegian&#x27;, &#x27;Tongan&#x27;]</td><td>AU</td><td>2013-08-19</td><td>Norwegian</td><td>48f9c924e0d98c959d8a6f1862b3ce9a</td><td>Norwegian</td></tr><tr><td>[&#x27;Danish&#x27;, &#x27;Dinka&#x27;, &#x27;Khmer&#x27;, &#x27;Lao&#x27;]</td><td>AU</td><td>2013-08-19</td><td>Dinka</td><td>af5e8f27cef9e689a070b8814dcc02c3</td><td>Dinka</td></tr><tr><td>[&#x27;German&#x27;, &#x27;Hungarian&#x27;, &#x27;Samoan&#x27;, &#x27;Turkish&#x27;]</td><td>AU</td><td>2013-08-19</td><td>Turkish</td><td>509c36eb58dbce009ccf93f375358d53</td><td>Samoan</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "-- test it out\n",
    "SELECT *\n",
    "FROM dataset_50k\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "Find all games such that the guessed language is correct (=target), and such that this language is Spanish. What is the length of the resulting sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 3269.97802734375,
      "end_time": 1573674917442.039
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">count(1)</td></tr><tr><td>1010</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT count(*) FROM dataset_50k\n",
    "WHERE target == \"Spanish\" \n",
    "AND target == guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "Find the number of all distinct values of the guessed languages (i.e. the guess field). What is the length of the resulting sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 5283.8310546875,
      "end_time": 1573674952324.165
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">count(DISTINCT guess)</td></tr><tr><td>68</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT count(distinct(guess))\n",
    "FROM dataset_50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "Return the top three games where the guessed language is incorrect ($\\ne$target) ordered by country (ascending), then target language (ascending), then date (ascending). What is the sample id of the 3rd item in the list? \n",
    "\n",
    "Enter it without quotes, for example 48f9c924e0d98c959d8a6f1862b3ce9a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 2259.453857421875,
      "end_time": 1573674971198.841
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">sample</td></tr><tr><td>ccebbc271377f7173e39564c74901f7c</td></tr><tr><td>7efab6f0c61694ba6e8aa72843d1bf15</td></tr><tr><td>3520fdcdf2658685928fc37e72ab2134</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT sample\n",
    "FROM dataset_50k as d\n",
    "WHERE guess != target\n",
    "ORDER BY country asc, target asc, d.date asc\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "Aggregate all games by guessed and target language, counting the number of guessing games that were done for each pair (guess, target). How many times has Dutch been mistaken for Norwegian (i.e. Dutch was the true answer)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 3281.450927734375,
      "end_time": 1573675065646.265
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">sample</td></tr><tr><td>5cd22cbf16be1a93d304d589431c3ec3</td></tr><tr><td>65bf2aceadf2520f36a5e548a0471fcf</td></tr><tr><td>bf0f1eec2e9f147aba20ea9b3e9564bb</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT count(guess)\n",
    "FROM dataset_50k \n",
    "GROUP BY country, target\n",
    "ORDER BY count(guess) desc\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5\n",
    "Among all the games where the guess was correct (=target), what is the percentage of cases where the second choice (among the array of possible answers) was the target?\n",
    "\n",
    "Please write the fraction rounding to 4 decimals (eg. 0.3323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 1265.067138671875,
      "end_time": 1573675200154.991
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">(count(1) / scalarsubquery())</td></tr><tr><td>0.2696</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT count(*) / \n",
    "(SELECT count(*) as c\n",
    "FROM dataset_50k)\n",
    "FROM dataset_50k\n",
    "WHERE choices[1] = target AND target = guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "How many games in France (country=FR) were played on the last day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 3271.09814453125,
      "end_time": 1573675296367.05
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">count(1)</td></tr><tr><td>93</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT count(*) \n",
    "FROM dataset_50k\n",
    "WHERE date = \n",
    "(SELECT max(date) FROM dataset_50k)\n",
    "AND country = \"FR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
